setwd('/Users/mariarosa/Documents/DataScienceTools/Rtutorials/')
k = 10
set.seed(1)
folds = sample(1:k,nrow(Hitters),replace=TRUE)
source('Tutorial5.R')
folds
k = 10
set.seed(1)
folds = sample(1:k,nrow(Hitters),replace=TRUE)
folds
cv.errors = matrix(NA,k,19,dimnames=list(NULL,paste(1:19)))
cv.errors
for (j in 1:k){
best.fit = regsubsets(Salary~.,data = Hitters[folds!=j,],nmax=19)
for (i in 1:19){
pred = predict(best.fit,Hitters[folds == j,],id=i)
cv.errors[j,i] = mean((Hitters$Salary[folds==j]-pred)^2)
}
}
for (j in 1:k){
best.fit = regsubsets(Salary~.,data = Hitters[folds!=j,],nmax=19)
for (i in 1:19){
#pred = predict(best.fit,Hitters[folds == j,],id=i)
#cv.errors[j,i] = mean((Hitters$Salary[folds==j]-pred)^2)
}
}
for (j in 1:k){
best.fit = regsubsets(Salary~.,data = Hitters[folds!=j,],nvmax=19)
for (i in 1:19){
#pred = predict(best.fit,Hitters[folds == j,],id=i)
#cv.errors[j,i] = mean((Hitters$Salary[folds==j]-pred)^2)
}
}
for (j in 1:k){
best.fit = regsubsets(Salary~.,data = Hitters[folds!=j,],nvmax=19)
for (i in 1:19){
pred = predict(best.fit,Hitters[folds == j,],id=i)
cv.errors[j,i] = mean((Hitters$Salary[folds==j]-pred)^2)
}
}
predict.regsubsets = function(object ,newdata ,id ,...){
form=as.formula(object$call[[2]])
mat=model.matrix(form,newdata)
coefi=coef(object ,id=id)
xvars=names(coefi)
mat[,xvars]%*%coefi
}
for (j in 1:k){
best.fit = regsubsets(Salary~.,data = Hitters[folds!=j,],nvmax=19)
for (i in 1:19){
pred = predict.regsubsets(best.fit,Hitters[folds == j,],id=i)
cv.errors[j,i] = mean((Hitters$Salary[folds==j]-pred)^2)
}
}
cv.errors
dim(cv.errors)
mean.cv.errors = apply(cv.errors,2,mean)
mean.cv.errors
par(mfrow=c(1,1))
plot(mean.cv.errors,type='b')
reg.best = regsubsets(Salary~.,data=Hitters,nvmax=19)
coef(reg.best,11)
?glmnet
install.packages('glmnet')
?glmnet
??glmnet
library(glmnet)
Hitters
rm(list=ls())
library(glmnet)
library(ISLR)
Hitters
names(Hitters)
t = is.nan(Hitters)
Hitters = na.omit(Hitters)
t = rand(3,4)
t = sample(3,4)
t = sample(3)
t
t = sample(3)[,-1]
t = sample(3)[-1]
t
names(Hitters)
Salary
x = model.matrix(Salary~.,Hitters)
dim(x)
x
names(Hitters)
Hitters
Hitters[1:10,1:10]
Hitters[1:10,]
Hitters[1:3,-1]
Hitters[1:3]
Hitters[1:3,]
Hitters[1:3,-1]
x = model.matrix(Salary~.,Hitters)
x[1:3,]
x[1:3,-1]
x = model.matrix(Salary~.,Hitters)[,-1]
x[1:3,-1]
x = model.matrix(Salary~.,Hitters)
x[1:3,]
x[1:3,-1]
x = model.matrix(Salary~.,Hitters)[,-1]
x[1:3,]
seq(10,2,length=100)
10^seq(10,2,length=100)
source('Tutorial5.R')
rm(list=ls())
source('Tutorial6.R')
source('Tutorial6.R')
ridge.mod
dim(coef(ridge.mod))
10^seq(10,2,length=100)
grid = 10^seq(10,-2,length=100)
ridge.mod = glmnet(x,y,alpha=0,lambda=grid)
dim(coef(ridge.mod))
ridge.mod$lambda[50]
coef(ridge.mod)[,50]
coef(ridge.mod)[-1,50]^2
coef(ridge.mod)[,50]^2
coef(ridge.mod)[-1,50]^2
coef(ridge.mod)[,50]
sqrt(sum(coef(ridge.mod)[-1,50]^2))
ridge.mod$lambda[60]
ridge.mod$lambda[60]
coef(ridge.mod)[,60]
sqrt(sum(coef(ridge.mod)[-1,60]^2))
predict(ridge.mod,s=50,type="coefficients")[1:20,]
predict(ridge.mod,s=50,type="coefficients")
?sample
sample(3,2)
sample(3,2)
sample(3,2)
set.seed(1)
train = sample(1:nrow(x),nrow(x)/2)
test = (-train)
train
test
t = sample(2,5)
t = sample(5,2)
t
t = sample(5,4)
t
t[-2]
t[-1]
t[-4]
ridge.mod = glmnet(x[train,],y[train],alpha=0,lambda=grid,thres=1e-12)
ridge.pred = predict(ridge.mod,s=4,newx=x[test,])
mean((ridge.pred-y.test)^2)
x
ridge.mod = glmnet(x[train,],y[train],alpha=0,lambda=grid,thres=1e-12)
ridge.pred = predict(ridge.mod,s=4,newx=x[test,])
mean((ridge.pred-y.test)^2)
ridge.pred
dim(ridge.pred)
dim(y.test)
set.seed(1)
train = sample(1:nrow(x),nrow(x)/2)
test = (-train)
y.test = y[test]
ridge.mod = glmnet(x[train,],y[train],alpha=0,lambda=grid,thres=1e-12)
ridge.pred = predict(ridge.mod,s=4,newx=x[test,])
mean((ridge.pred-y.test)^2)
mean(y[train])
mean((y[train]-y.test)^2)
mean((mean(y[train])-y.test)^2)
mean((mean(y[train])-y.test)^2)
mean((mean(y[train])-y.test)^2)
ridge.pred=predict(ridge.mod,s=1e10,newx=x[test,])
mean((ridge.pred-y.test)^2)
ridge.pred = (ridge.mod,s=0,newx=[test,],exact=T)
mean((ridge.pred-y.test)^2)
ridge.pred = (ridge.mod,s=0,newx=x[test,],exact=T)
mean((ridge.pred-y.test)^2)
ridge.pred = (ridge.mod,s=0,newx=x[test,],exact=T)
mean((ridge.pred-y.test)^2)
ridge.mod = glmnet(x[train,],y[train],alpha=0,lambda=grid,thres=1e-12)
ridge.pred = predict(ridge.mod,s=4,newx=x[test,])
mean((ridge.pred-y.test)^2)
# Model with intercept only (=mean)
mean((mean(y[train])-y.test)^2)
ridge.pred=predict(ridge.mod,s=1e10,newx=x[test,])
mean((ridge.pred-y.test)^2)
# Compare with linear regression
ridge.pred = (ridge.mod,s=0,newx=x[test,],exact=T)
mean((ridge.pred-y.test)^2)
ridge.pred = (ridge.mod ,s=0,newx=x[test,],exact=T)
ridge.pred = predict(ridge.mod ,s=0,newx=x[test,],exact=T)
mean((ridge.pred-y.test)^2)
lm(y~x,subset=train)
predict(ridge.mod,s=0,exact=T,type="coefficients")[1:20,]
set.seed(1)
cv.out = cv.glmnet(x[train,],y[train],alpha=0)
plot(cv.out)
bestlam = cv.out$lambda.min
bestlam
set.seed(1)
cv.out = cv.glmnet(x[train,],y[train],alpha=0)
plot(cv.out)
bestlam = cv.out$lambda.min
bestlam
set.seed(1)
cv.out = cv.glmnet(x[train,],y[train],alpha=0)
plot(cv.out)
bestlam = cv.out$lambda.min
bestlam
cv.out
plot(cv.out)
